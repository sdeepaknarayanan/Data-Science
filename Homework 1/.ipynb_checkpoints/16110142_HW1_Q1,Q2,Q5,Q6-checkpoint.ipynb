{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1. Expectation Maximization Data Generation\n",
    "Submitted by S Deepak Narayanan, 16110142<br/>\n",
    "Collaborators: Varun Gohil, Ritik Dutta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal\n",
    "from sklearn.datasets import make_spd_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "cf = open('Dataset01/centers.txt','r')\n",
    "count = 0\n",
    "centers = []\n",
    "for i in cf:\n",
    "    if count==0:\n",
    "        count=1\n",
    "        arr = i.split(',')\n",
    "        gaussians = int(arr[0])\n",
    "        dimension = int(arr[1])\n",
    "    elif count==1:\n",
    "        weights = ((i.split(',')))\n",
    "        count+=1\n",
    "    else:\n",
    "        centers.append(i.split(','))\n",
    "        count+=1\n",
    "cf.close()\n",
    "for i in range(len(centers)):\n",
    "    centers[i].remove('\\n')\n",
    "weights.remove('\\n')\n",
    "for i in range(len(weights)):\n",
    "    weights[i] = float(weights[i])\n",
    "for i in range(len(centers)):\n",
    "    for j in range(len(centers[i])):\n",
    "        centers[i][j] = float(centers[i][j])\n",
    "centers = np.array(centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariance = []\n",
    "for i in range(1,11):\n",
    "    covariance.append(np.loadtxt('Dataset01/cov_'+str(i)+'.txt', delimiter=',',    comments='# '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixture = np.random.choice(10,1000, p=weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnt = 0\n",
    "samples = []\n",
    "for i in mixture:\n",
    "    cnt+=1\n",
    "    temp = (np.random.multivariate_normal(centers[i],covariance[i],1)[0])\n",
    "    samples.append((i,temp))\n",
    "## This commented code is used to dump the needed file\n",
    " \"\"\"\n",
    "    file = open('1.txt','a')\n",
    "    file.write('(' + str(i)+',')\n",
    "    for i in range(len(temp)):\n",
    "        file.write(str(temp[i])+' ')\n",
    "    file.write(')\\n')\n",
    "    file.close()\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2 Expectation Maximization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = {}\n",
    "for i in mixture:\n",
    "    if i not in prior:\n",
    "        prior[i] = 1\n",
    "    else:\n",
    "        prior[i]+=1\n",
    "for i in prior:\n",
    "    prior[i] = prior[i]/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Initial Prioir - Set to equal to all the samples to be from all the gaussians\n",
    "init_prior = {i:0.1 for i in range(10)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = [np.ones(500)*j for j in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "covars = [np.eye(500)*10 for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob(covar,mean,x,d):\n",
    "    coeff = 1/((2*np.pi)**(d/2)*(np.abs(np.linalg.det(covar)))**0.5)\n",
    "    val = np.exp(-0.5*((np.transpose(x-mean).dot((np.linalg.pinv((covar)))).dot((x-mean)))))\n",
    "    return val*coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deepak/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:2022: RuntimeWarning: overflow encountered in det\n",
      "  r = _umath_linalg.det(a, signature=signature)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0 0.0\n",
      "1 0.0 0.0\n",
      "2 0.0 0.0\n",
      "3 0.0 0.0\n",
      "4 0.0 0.0\n",
      "5 0.0 0.0\n",
      "6 0.0 0.0\n",
      "7 0.0 0.0\n",
      "8 0.0 0.0\n",
      "9 0.0 0.0\n"
     ]
    }
   ],
   "source": [
    "## Creating a dictionary of the Gaussian Weights\n",
    "gauss_weights = {i:np.zeros(len(samples)) for i in range(10)}\n",
    "for curr_gaussian in range(10):\n",
    "    for i in range(len(samples)):\n",
    "        cond_prob = prob(covars[curr_gaussian],means[curr_gaussian],samples[i][1],500)\n",
    "        numerator = cond_prob*init_prior[curr_gaussian]\n",
    "        gauss_weights[curr_gaussian][i] = numerator\n",
    "    print(curr_gaussian,cond_prob,numerator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As can be seen above, when generating the needed probabilities, I am getting an overflow/underflow error, due to which I wan't able to perform EM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Storing the weights\n",
    "gb_temp = []\n",
    "for i in range(len(samples)):\n",
    "    temp = 0\n",
    "    for j in gauss_weights:\n",
    "        temp+=gauss_weights[j][i]\n",
    "    gb_temp.append((i,temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def expectation_maximisation(samples,means,covars,number_iters):\n",
    "    cov_curr_err = [np.linalg.norm(covars[i] - covariance[i]) for i in range(10)]\n",
    "    mean_curr_err = [np.linalg.norm(means[i] - centers[i]) for i in range(10)]\n",
    "    for iteration in range(10):\n",
    "        gauss_weights = {i:np.zeros(len(samples)) for i in range(10)}\n",
    "        for curr_gaussian in range(10):\n",
    "            for i in range(len(samples)):\n",
    "                cond_prob = prob(covars[curr_gaussian],means[curr_gaussian],samples[i][1],500)\n",
    "                numerator = cond_prob*init_prior[curr_gaussian]\n",
    "                gauss_weights[curr_gaussian][i] = numerator\n",
    "            print(curr_gaussian,cond_prob,numerator)\n",
    "\n",
    "        gb_temp = []\n",
    "        for i in range(len(samples)):\n",
    "            temp = 0\n",
    "            for j in gauss_weights:\n",
    "                temp+=gauss_weights[j][i]\n",
    "            gb_temp.append((i,temp))\n",
    "\n",
    "        gauss_weights_1 = gauss_weights.copy()\n",
    "\n",
    "        for i in range(len(gb_temp)):\n",
    "            for j in gauss_weights_1:\n",
    "                gauss_weights_1[j][gb_temp[i][0]]/=gb_temp[i][1]\n",
    "\n",
    "        for i in range(len(gb_temp)):\n",
    "            for j in gauss_weights_1:\n",
    "                gauss_weights_1[j][gb_temp[i][0]]/=gb_temp[i][1]\n",
    "\n",
    "        for curr_gaussian in range(10):\n",
    "            temp = np.zeros(500)\n",
    "            for i in range(len(samples)):\n",
    "                temp+=gauss_weights_1[curr_gaussian][i]*samples[i]\n",
    "            temp/=gauss_weights_1[curr_gaussian].sum()\n",
    "            means[curr_gaussian] = temp\n",
    "\n",
    "        for curr_gaussian in range(10):\n",
    "            new_cov = np.zeros((500,500))\n",
    "            for i in range(samples):\n",
    "                new_cov+=gauss_weights_1[curr_gaussian][i]*(samples[i] - means[curr_gaussian]).dot(np.transpose(samples[i] - means[curr_gaussian]))\n",
    "            new_cov/=gauss_weights_1[curr_gaussian].sum()\n",
    "            covars[curr_gaussian] = new_cov\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q5 - Markov's Inequality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know the following for a string of length $n$, we have $2^{n}$ possible arrangements of the string. <br/>\n",
    "Let the worst case running time be $W$. <br/>\n",
    "What we do know about $W$ is the fact that it is the time taken by the input algorithm for at least one of the $2^n$ possible input strings. <br/>\n",
    "Let us denote the running time of the algorithm as $T$. Here $T$ can be seen as a random variable whose value changes as the input strings change.<br/><br/>\n",
    "Therefore, we claim the following: <br/> <br/>\n",
    "$Pr[T > W] < \\frac{1}{2^{n}}$, where $n$ is the length of the string. <br/>\n",
    "This claim is true simply because of the fact that $W$ has to occur on atleast one of the strings. This statement in essence says that there is no string for which the running time is bigger than $W$.\n",
    "<br/> From Markov's inequality, $Pr[T > W] \\leq \\frac{E[T]}{W} $. $E[T] = O(n^{2})$, as per the question.<br/><br/>\n",
    "This implies that $Pr[T > W] \\leq \\frac{E[T]}{W} = \\frac{O(n^{2})}{W} < \\frac{1}{2^{n}}$ <br/><br/>\n",
    "This implies that $W < O(n^{2}).2^{n} \\implies W < O(2^{n}n^{2})$. <br/><br/>\n",
    "Therefore from Markov's inequality, we know that $W = O(2^{n}n^{2})$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q6 Doubts or Unclear Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Equator Theorem - In particular - how does the bound ensure that most of the points are inside the equator, and also its relation to how most of the sampled points of a d-dimensional gaussian is both at the annulus as well as at the equator.\n",
    "2. Applications of various bounds/concentration inequalities when given a problem. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
